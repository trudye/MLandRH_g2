---
title: "ERF as AKI predictor"
output: html_notebook
---
```{r}
#setwd("C:/Users/maxgg/OneDrive/VU/ML_reasoning/MLreasoningdata") 

# Libraries

# #atemt to load from the github
library(htmltools)
library(devtools)

library(gbm)
library(inTrees)
library(randomForest)
library(pROC)
library(MASS)
library(bayesm)
library(glmnet)
library(coefplot)
library(purrr)
library(rlist)
library(tidyverse)
library(caret)
library(mlbench)
library(Metrics)

#Change the next line the folder where you have stored this project.

source("erf_auxilaries.R")

```


```{r}
conf_rules <- c(
                "heightgroup_159. == 1 & weightgroup_70.79 == 1 & baseline_sepsis == 1 & baseline_ABP <= 90",
                "heightgroup_160.169 == 1 & weightgroup_80.89 == 1 & baseline_sepsis == 1 & baseline_ABP <= 90",
                "heightgroup_170.179 == 1 & weightgroup_100.109 == 1 & baseline_sepsis == 1 & baseline_ABP <= 90",
                "heightgroup_180.189 == 1 & weightgroup_110. == 1 & baseline_sepsis == 1 & baseline_ABP <= 90",
                  "sepsis_inIC == 1",
                
                  "heightgroup_159. == 1 & weightgroup_70.79 == 1",
                "heightgroup_160.169 == 1 & weightgroup_80.89 == 1",
                "heightgroup_170.179 == 1 & weightgroup_100.109 == 1",
                "heightgroup_180.189 == 1 & weightgroup_110. == 1",
                
                "baseline_ABP <= 90 & agegroup_70.79 == 1 & specialty == 'Nefrologie'",
               "baseline_ABP <= 90 & agegroup_80. == 1 & specialty == 'Nefrologie'")

opt_rules <- c("baseline_ABP <= 90 & agegroup_70.79 == 1 & specialty == 'Nefrologie'",
               "baseline_ABP <= 90 & agegroup_80. == 1 & specialty == 'Nefrologie'")

```


```{r}
y_train <- read.csv("Y_train.csv")
y_train
y_train$AKI_stage <- as.factor(y_train$AKI_stage)

y_train$stage0 <- as.factor(ifelse(y_train$AKI_stage == '0', 1, 0))
y_train$stage1 <- as.factor(ifelse(y_train$AKI_stage == '1', 1, 0))
y_train$stage2 <- as.factor(ifelse(y_train$AKI_stage == '2', 1, 0))
y_train$stage3 <- as.factor(ifelse(y_train$AKI_stage == '3', 1, 0))


y_test <- read.csv("Y_test.csv")
y_test$AKI_stage <- as.factor(y_test$AKI_stage)

y_test$stage0 <- as.factor(ifelse(y_test$AKI_stage == '0', 1, 0))
y_test$stage1 <- as.factor(ifelse(y_test$AKI_stage == '1', 1, 0))
y_test$stage2 <- as.factor(ifelse(y_test$AKI_stage == '2', 1, 0))
y_test$stage3 <- as.factor(ifelse(y_test$AKI_stage == '3', 1, 0))

x_train <- read.csv("X_train.csv")

x_test <- read.csv("X_test.csv")

# Remove rows with missing values from y_train
y_train <- na.omit(y_train)

# Identify rows to remove from x_train based on the missing rows in y_train
rows_to_remove <- setdiff(1:nrow(x_train), match(rownames(y_train), rownames(x_train)))

# Remove corresponding rows from x_train
x_train <- x_train[-rows_to_remove, ]


#And now for test.
# Remove rows with missing values from y_test
y_test <- na.omit(y_test)

# Identify rows to remove from x_train based on the missing rows in y_test
rows_to_remove <- setdiff(1:nrow(x_test), match(rownames(y_test), rownames(x_test)))

# Remove corresponding rows from x_test
x_test <- x_test[-rows_to_remove, ]

x_train$specialty <- as.factor(x_train$specialty)
x_test$specialty <- as.factor((x_test$specialty))

```


```{r}
ExpertRuleFit = function(X=NULL, y=NULL, Xtest=NULL, ytest=NULL, intercept=T,
                         optional_expert_rules = NULL, confirmatory_expert_rules = NULL,  
                         optional_linear_terms=NULL, confirmatory_linear_terms = NULL,
                         expert_only = F, optional_penalty = 1, ntree=250, 
                         ensemble= "GBM", mix=0.5, L=3, S=6, minsup=.025, corelim = 1, 
                         alpha = 0.9, s = "lambda.1se", standardize = F,
                         n_imp = 10, print_output = T) {
  
  # combine optional and confirmatory EK 
  all_expert_rules <- c(optional_expert_rules, confirmatory_expert_rules)
  all_linear_terms <- c(optional_linear_terms, confirmatory_linear_terms)
  
  
  # function input checks
  if((is.matrix(X)|is.data.frame(X))==F){
    stop("X must be a matrix or data frame.")
  }
  
  if((!is.factor(y))){
    stop("y is not a (binary) factor. Currently only (binary) classification is supported.")
  }
  
  if(!(is.null(Xtest))){
    if(dim(X)[2]!= dim(Xtest)[2]){
      stop("The dimensionality between X and Xtest differs.")
    }
  }
  
  if(is.null(ytest)==F){
    if(mode(y)!=mode(ytest)){
      stop("The mode of y and ytest differs.")
    }
  }
  
  if(!(is.null(all_expert_rules))){
      all_expert_rules <- names_to_positions(X, all_expert_rules)
  } 
  
  if(!(is.null(optional_expert_rules))){
      optional_expert_rules <- names_to_positions(X, optional_expert_rules)
  } 
  
  if(!(is.null(confirmatory_expert_rules))){
      confirmatory_expert_rules <- names_to_positions(X, confirmatory_expert_rules)
  } 
  
  if(!(is.null(all_linear_terms))){
    all_linear_terms <- names_to_numbers(X, all_linear_terms)
    for(l in 1:length(all_linear_terms)){
      if(is.numeric(X[,all_linear_terms[l]])==F){
        stop(sprintf("Variable %i is not numeric and can not be included as
                     linear term. Please check the variable.",l))
      }
    }
  }
  
  if(!(is.null(optional_linear_terms))){
    optional_linear_terms <- names_to_numbers(X, optional_linear_terms)
    optional_linear_terms <- paste("X[,",optional_linear_terms, "]", sep = "") 
  }
  
  
  
  if(!(is.null(confirmatory_linear_terms))){
    confirmatory_linear_terms <- names_to_numbers(X, confirmatory_linear_terms)
    confirmatory_linear_terms <- paste("X[,",confirmatory_linear_terms, "]", sep = "") 
  }
  
  
  if(ntree<2){
    stop("Too few trees are chosen for ExpertRuleFit.")
  }
  
  
  if((mix<0)|(mix>=1)){
    stop("invalid choice for mix, please chose a value between 0 and 1.")
  }
  
  if(L<2){
    stop("Parameter L needs to be >=2.")
  }
  
  if(S<1){
    stop("Parameter S needs to be >=1.")
  }
  
  if((minsup<0)|(minsup>=1)){
    stop("invalid choice for minimum support, please chose a 
         value between 0 and 1.")
  }
  
  
  if(is.logical(intercept)==F){
    stop("Invalid intercept choice. Must be TRUE or FALSE.")
  }
  
  
  if((alpha<0)|(alpha>1)){
    stop("invalid choice for alpha, please chose a value between 0 and 1.")
  }
  
  
  if(is.logical(print_output)==F){
    stop("Invalid choice regarding output print. Must be TRUE or FALSE.")
  }
  
  N = length(y)

  if(expert_only == T){
    dt = createX(X = X, rules = all_expert_rules, t = 0, corelim = 1)
    Xr = dt[[1]]
    rulesFin = dt[[2]]
  }else{
    if (ensemble == "RF") {
      capture.output(rulesf <- genrulesRF(X, y, nt=ntree, S=S, L=L))
    } else if (ensemble == "GBM") {
      capture.output(rulesf <- genrulesGBM(X, y, nt=ntree,S=S, L=L))
    } else if (ensemble == "both"){
      capture.output(rules1 <- genrulesRF(X, y, nt=round(ntree*mix),
                                          S=S, L=L))
      capture.output(rules2 <- genrulesGBM(X, y, nt=round(ntree*(1-mix)),
                                           S=S, L=L))
      rulesf = c(rules1, rules2)
    } else {
      print("invalid Tree ensemble choice")
    }
    
    # add expert rules to rule ensemble if present
    if(!(is.null(all_expert_rules))){
      rulesf <- c(rulesf, all_expert_rules)
    }
    
    dt = createX(X = X, rules = rulesf, t = minsup, corelim = corelim)
    Xr = dt[[1]]
    rulesFin = dt[[2]]
  }
  

  if (!(is.null(all_expert_rules))){
    removed_expertrules <- c()
    for (i in 1:length(all_expert_rules)){
      if(!(all_expert_rules[i] %in% rulesFin)){
        removed_expertrules <- c(removed_expertrules, all_expert_rules[i])
      }
    }
    removed_expertrules
  } else{
    removed_expertrules <- NULL
  }
  
  
  # standardize linear terms 
  sdl=0
  mul=0
  
  if(length(all_linear_terms)>1){
    mul = apply(X[,all_linear_terms], 2, mean)
    sdl = apply(X[,all_linear_terms], 2, sd)
    for(l in 1:length(all_linear_terms)){
      X[,all_linear_terms[l]] = 0.4*((X[,all_linear_terms[l]]-mul[l])/sdl[l])
    }
  } else if(length(all_linear_terms)==1){
    mul = mean(X[,all_linear_terms])
    sdl = sd(X[,all_linear_terms])
    X[,all_linear_terms] = 0.4*((X[,all_linear_terms] - mul)/sdl)
  }
  
  # add linear terms and intercept (optional) to rule matrix Xt
  if(is.null(all_linear_terms)){
    if(intercept==TRUE){
      Xt = as.data.frame(cbind(rep(1, times= dim(Xr)[1]),Xr))
    } else{
      Xt = as.data.frame(Xr)
    }
  } else{
    if(intercept==TRUE){
      Xt = as.data.frame(cbind(rep(1, times=dim(X)[1]), X[,all_linear_terms], Xr))
    } else{
      Xt = as.data.frame(cbind(X[,all_linear_terms], Xr))
    }
  } 
  

  
  # change column names: intercept = X0, linear terms = X1,...Xp, rules as specified conditions
  if((intercept == TRUE) & (!(is.null(all_linear_terms)))){
    colnames(Xt)[1] <- "Intercept"
    colnames(Xt)[2:(length(all_linear_terms)+1)] <- paste("X[,",all_linear_terms, "]", sep = "") 
    colnames(Xt)[(length(all_linear_terms)+2): ncol(Xt)] <- rulesFin
  } else if ((intercept == TRUE) & (is.null(all_linear_terms))){
    colnames(Xt)[1] <- "Intercept"
    colnames(Xt)[2: ncol(Xt)] <- rulesFin
  } else if ((intercept == FALSE) & (!(is.null(all_linear_terms)))){
    colnames(Xt)[1:length(all_linear_terms)] <- paste("X[,",all_linear_terms, "]", sep = "")
    colnames(Xt)[(length(all_linear_terms)+1): ncol(Xt)] <- rulesFin
  } else{ 
    colnames(Xt) <- rulesFin
  }
  
  
  # get the column indices of the confirmatory terms
  if((!(is.null(confirmatory_expert_rules))) & (!(is.null(confirmatory_linear_terms)))){
    confirmatory_terms <- c(confirmatory_expert_rules, confirmatory_linear_terms)
  } else if ((is.null(confirmatory_expert_rules)) & (!(is.null(confirmatory_linear_terms)))){
    confirmatory_terms <- confirmatory_linear_terms
  } else if ((!(is.null(confirmatory_expert_rules))) & (is.null(confirmatory_linear_terms))){
    confirmatory_terms <- confirmatory_expert_rules
  } else {
    confirmatory_terms <- NULL
  }
  
  if(!(is.null(confirmatory_terms))){
    confirmatory_cols <- c()
    for(i in 1: length(confirmatory_terms)){
      if(confirmatory_terms[i] %in% colnames(Xt)){
        confirmatory_cols <- c(confirmatory_cols, which(colnames(Xt) == confirmatory_terms[i]))
      }
    }
  } else{
    confirmatory_cols <- NULL
  }
  
  
  # get the column indices of the optional terms
  if((!(is.null(optional_expert_rules))) & (!(is.null(optional_linear_terms)))){
    optional_terms <- c(optional_expert_rules, optional_linear_terms)
  } else if ((is.null(optional_expert_rules)) & (!(is.null(optional_linear_terms)))){
    optional_terms <- optional_linear_terms
  } else if ((!(is.null(optional_expert_rules))) & (is.null(optional_linear_terms))){
    optional_terms <- optional_expert_rules
  } else {
    optional_terms <- NULL
  }
  
  if(!(is.null(optional_terms))){
    optional_cols <- c()
    for(i in 1: length(optional_terms)){
      if(optional_terms[i] %in% colnames(Xt)){
        optional_cols <- c(optional_cols, which(colnames(Xt) == optional_terms[i]))
      }
    }
  } else{
    optional_cols <- NULL
  }
  
  
  
  if(is.null(Xtest) == T){
    regmodel = regularized_regression(X=Xt, y=y, Xtest = NULL, ytest =NULL,
                                      s = s,
                                      confirmatory_cols = confirmatory_cols,
                                      optional_cols = optional_cols,
                                      optional_penalty = optional_penalty,
                                      alpha = alpha, standardize = standardize,
                                      n = n_imp, 
                                      print_output = print_output)
    
    
    # EK INFO
    # all ensemble members (rules + linear terms)
    model_features <- regmodel$Results$features
    
    # the n_imp most important ensemble members (=features)
    imp_features <- regmodel$ImpFeatures
    
    # optional EK among the most important features
    opt_ek <- c(optional_expert_rules, optional_linear_terms)
    opt_ek_imp <- contains(opt_ek, imp_features)
    
    # Expert rules removed due to too low/high support on data
    opt_er_names <- positions_to_names(X, optional_expert_rules)
    unsup_er <- support_remove(opt_er_names, rbind.data.frame(X,y), minsup)
    unsup_er <- names_to_positions(X, unsup_er)
    
    removed_as_unsup <- contains(unsup_er, removed_expertrules)
    removed_as_corr <- setdiff(removed_expertrules, removed_as_unsup)
    
    
    # confirmatory EK among the most important features
    conf_ek <- c(confirmatory_expert_rules, confirmatory_linear_terms)
    conf_ek_imp <- contains(conf_ek, imp_features)
    
    # proportion of EK among most imp. features
    prop_ek_imp <- length(c(opt_ek_imp, conf_ek_imp))/n_imp
    
    # optional EK in the final model
    opt_ek_in <- contains(opt_ek, model_features)
    
    # confirmatory EK in the final model
    conf_ek_in <- contains(conf_ek, model_features)
    
    # all EK in the final model
    all_ek_in <- c(opt_ek_in, conf_ek_in)
    
    
    # proportion of optional EK/EK among all EK/all features
    prop_opt_ek <- length(opt_ek_in)/(regmodel$NTerms)
    prop_all_ek <- length(all_ek_in)/(regmodel$NTerms)
    
    
    if(print_output == T){
      reg_info <- regression_output(X, Xtest = NULL, regmodel)
      exp_info <- expert_output(X = X, opt_ek_imp = opt_ek_imp, conf_ek_imp = conf_ek_imp,
                                n_imp = n_imp, prop_ek_imp = prop_ek_imp,
                                opt_ek_in = opt_ek_in, conf_ek_in = conf_ek_in, 
                                removed_as_unsup = removed_as_unsup,
                                removed_as_corr = removed_as_corr,
                                prop_opt_ek = prop_opt_ek, prop_all_ek = prop_all_ek)
      output <- list(reg_info, exp_info)
      
    }
    

    regmodel$Results$features <- positions_to_names(X, regmodel$Results$features)
    regmodel$ImpFeatures <- positions_to_names(X, regmodel$ImpFeatures)
    importantek <- positions_to_names(X, c(opt_ek_imp, conf_ek_imp))
    opt_ek_in <- positions_to_names(X, opt_ek_in)
    conf_ek_in <- positions_to_names(X, conf_ek_in)
    removedek <- positions_to_names(X, c(removed_as_unsup, removed_as_corr))
    
    out = list(Train = Xt , 
            Model = regmodel$Results, 
            Features = regmodel$Results$features, 
            Coefficients = regmodel$Results$coefficients, 
            NTerms = regmodel$NTerms,
            AvgRuleLength = regmodel$AvgRuleLength,
            ImportantFeatures = regmodel$ImpFeatures,
            ImportantEK = importantek,
            PropEKImp = prop_ek_imp,
            OptionalEK = opt_ek_in,
            ConfirmatoryEK = conf_ek_in,
            RemovedEK = removedek, 
            PropOptionalEK = prop_opt_ek, 
            PropEK = prop_all_ek)
    
    # give training data original column names
    colnames(out$Train) <- positions_to_names(X, colnames(out$Train))
    
    
  }else{
    
    #create rules.
    Xrt = createXtest(Xtest, rulesFin)
    
    ##preparing test data set. Standardize linear terms Xtest
    if(!(is.null(all_linear_terms))){
      for(l in 1:length(all_linear_terms)){
        Xtest[,all_linear_terms[l]] = 0.4*((Xtest[,all_linear_terms[l]]-mul[l])/sdl[l])
      }
    }
    
    #combine to data frame
    if(is.null(all_linear_terms)){
      if(intercept==TRUE) {
        X_test = as.data.frame(cbind(rep(1, times = dim(Xrt)[1]), Xrt))
      }else{X_test = Xrt}
    } else {
      if(intercept==TRUE) {
        X_test = as.data.frame(cbind(rep(1, times = dim(Xrt)[1]), Xtest[,all_linear_terms], Xrt))
      }else{
        X_test = as.data.frame(cbind(Xtest[,all_linear_terms], Xrt))
      }
    }
    
    
    # adapt column names
    if((intercept == TRUE) & (!(is.null(all_linear_terms)))){
      colnames(X_test)[1] <- "Intercept"
      colnames(X_test)[2:(length(all_linear_terms)+1)] <- paste("X[,",all_linear_terms, "]", sep = "") 
      colnames(X_test)[(length(all_linear_terms)+2): ncol(X_test)] <- rulesFin
    } else if ((intercept == TRUE) & (is.null(all_linear_terms))){
      colnames(X_test)[1] <- "Intercept"
      colnames(X_test)[2: ncol(X_test)] <- rulesFin
    } else if (intercept == FALSE & (!(is.null(all_linear_terms)))){
      colnames(X_test)[1:length(all_linear_terms)] <- paste("X[,",all_linear_terms, "]", sep = "")
      colnames(X_test)[(length(all_linear_terms)+1): ncol(X_test)] <- rulesFin
    } else{      
      colnames(X_test) <- rulesFin
    }
    
    #if(expert_only == T){
      #print(colnames(X_test))
      #keep_all <- c(all_expert_rules, optional_linear_terms, confirmatory_linear_terms)
      #print(keep_all)
      #keep_in <- names(X_test)[(names(X_test) %in% keep_all)]
      #print(keep_in)
      #X_test <- subset(X_test, select = keep_in)
    #}
    
    
    # add prediction and error to model output
    regmodel = regularized_regression(X = Xt, y = y, Xtest = X_test,
                                      ytest = ytest, 
                                      s = s,
                                      confirmatory_cols = confirmatory_cols,
                                      optional_cols = optional_cols,
                                      optional_penalty = optional_penalty,
                                      alpha = alpha,
                                      standardize = standardize, n = n_imp,
                                      print_output = print_output)
    
    
    # EK INFO
    
    # all ensemble members (rules + linear terms)
    model_features <- regmodel$Results$features
    
    # the n_imp most important ensemble members (=features)
    imp_features <- regmodel$ImpFeatures
    
    # optional EK among the most important features
    opt_ek <- c(optional_expert_rules, optional_linear_terms)
    opt_ek_imp <- contains(opt_ek, imp_features)
    
    # Expert rules removed due to too low/high support on data
    opt_er_names <- positions_to_names(X, optional_expert_rules)
    unsup_er <- support_remove(opt_er_names, rbind.data.frame(X,y), minsup)
    unsup_er <- names_to_positions(X, unsup_er)
    
    removed_as_unsup <- contains(unsup_er, removed_expertrules)
    removed_as_corr <- setdiff(removed_expertrules, removed_as_unsup)
    
    
    # confirmatory EK among the most important features
    conf_ek <- c(confirmatory_expert_rules, confirmatory_linear_terms)
    conf_ek_imp <- contains(conf_ek, imp_features)
    
    # proportion of EK among most imp. features
    prop_ek_imp <- length(c(opt_ek_imp, conf_ek_imp))/n_imp
    
    # optional EK in the final model
    opt_ek_in <- contains(opt_ek, model_features)
    
    # confirmatory EK in the final model
    conf_ek_in <- contains(conf_ek, model_features)
    
    # all EK in the final model
    all_ek_in <- c(opt_ek_in, conf_ek_in)
    
    
    # proportion of optional EK/EK among all EK/all features
    prop_opt_ek <- length(opt_ek_in)/(regmodel$NTerms)
    prop_all_ek <- length(all_ek_in)/(regmodel$NTerms)
    
    
    if(print_output == T){
      reg_info <- regression_output(X, Xtest, regmodel)
      exp_info <- expert_output(X = X, opt_ek_imp = opt_ek_imp, conf_ek_imp = conf_ek_imp,
                                n_imp = n_imp, prop_ek_imp = prop_ek_imp,
                                opt_ek_in = opt_ek_in, conf_ek_in = conf_ek_in, 
                                removed_as_unsup = removed_as_unsup,
                                removed_as_corr = removed_as_corr,
                                prop_opt_ek = prop_opt_ek, prop_all_ek = prop_all_ek)
      output <- list(reg_info, exp_info)
      
    }
    
    regmodel$Results$features <- positions_to_names(X, regmodel$Results$features)
    regmodel$ImpFeatures <- positions_to_names(X, regmodel$ImpFeatures)
    importantek <- positions_to_names(X, c(opt_ek_imp, conf_ek_imp))
    opt_ek_in <- positions_to_names(X, opt_ek_in)
    conf_ek_in <- positions_to_names(X, conf_ek_in)
    removedek <- positions_to_names(X, c(removed_as_unsup, removed_as_corr))
    
    out = list(Train = Xt, 
            Test = X_test,
            Model = regmodel$Results, 
            Features = regmodel$Results$features, 
            Coefficients = regmodel$Results$coefficients, 
            NTerms = regmodel$NTerms,
            Predictions = regmodel$Predictions,
            AvgRuleLength = regmodel$AvgRuleLength,
            ConfusionMatrix = regmodel$ConfusionMatrix, 
            AUC = regmodel$AUC, 
            ClassErr = regmodel$CE,
            ImportantFeatures = regmodel$ImpFeatures,
            ImportantEK = importantek,
            PropEKImp = prop_ek_imp,
            OptionalEK = opt_ek_in,
            ConfirmatoryEK = conf_ek_in,
            RemovedEK = removedek, 
            PropOptionalEK = prop_opt_ek, 
            PropEK = prop_all_ek)
   
    # change column names back to original names 
    colnames(out$Train) <- positions_to_names(X, colnames(out$Train))
    colnames(out$Test) <- positions_to_names(X, colnames(out$Test))
    
  }
  

  
  class(out) = "ExpertRulemodel"
  
  out
}
```


```{r}
set.seed(42)
aki0_erf_model <- ExpertRuleFit(X = x_train[,4:24], y = y_train$stage0, Xtest = x_test[,4:24], ytest = y_test$stage0, intercept=T,
                              confirmatory_expert_rules = NULL, 
                              optional_expert_rules = NULL,
                              confirmatory_linear_terms = NULL, 
                              optional_linear_terms = NULL,
                              optional_penalty = 1, expert_only = F, 
                              ntree=250, ensemble= "GBM",mix=0.5, L=3, S=6,
                              minsup=.025, corelim = 1, alpha = 1,
                              s = "lambda.1se", n_imp = 10, 
                              print_output = T)
set.seed(42)
aki1_erf_model <- ExpertRuleFit(X = x_train[,4:24], y = y_train$stage1, Xtest = x_test[,4:24], ytest = y_test$stage1, intercept=T,
                              confirmatory_expert_rules = NULL, 
                              optional_expert_rules = NULL,
                              confirmatory_linear_terms = NULL, 
                              optional_linear_terms = NULL,
                              optional_penalty = 1, expert_only = F, 
                              ntree=250, ensemble= "GBM",mix=0.5, L=3, S=6,
                              minsup=.025, corelim = 1, alpha = 1,
                              s = "lambda.1se", n_imp = 10, 
                              print_output = T)
set.seed(42)
aki2_erf_model <- ExpertRuleFit(X = x_train[,3:26], y = y_train$stage2, Xtest = x_test[,3:26], ytest = y_test$stage2, intercept=T,
                              confirmatory_expert_rules = conf_rules, 
                              optional_expert_rules = NULL,
                              confirmatory_linear_terms = NULL, 
                              optional_linear_terms = NULL,
                              optional_penalty = 1, expert_only = F, 
                              ntree=250, ensemble= "GBM",mix=0.5, L=3, S=6,
                              minsup=.025, corelim = 1, alpha = 1,
                              s = "lambda.1se", n_imp = 10, 
                              print_output = T)
set.seed(42)
aki3_erf_model <- ExpertRuleFit(X = x_train[,3:26], y = y_train$stage3, Xtest = x_test[,3:26], ytest = y_test$stage3, intercept=T,
                              confirmatory_expert_rules = conf_rules, 
                              optional_expert_rules = NULL,
                              confirmatory_linear_terms = NULL, 
                              optional_linear_terms = NULL,
                              optional_penalty = 1, expert_only = F, 
                              ntree=250, ensemble= "GBM",mix=0.5, L=3, S=6,
                              minsup=.025, corelim = 1, alpha = 1,
                              s = "lambda.1se", n_imp = 10, 
                              print_output = T)
```


```{r}
#AKI0
aki0_erf_model$AUC
#AKI1
aki1_erf_model$AUC
#AKI2
aki2_erf_model$AUC
#AKI3
aki3_erf_model$AUC
```

